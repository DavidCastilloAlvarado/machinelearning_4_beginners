#%%
import numpy as np 
import matplotlib.pyplot as plt
from math import cos, sin,pi
import random as rn 
from sklearn.model_selection import train_test_split

#%%
# DATA SET
# Creando puntos aleatorios para la primera clase, tomando un punto
# como referencia
# 
rn.seed(5)
c_NO = (8.5,8.5)
theta = [rn.random()*2*pi for _ in range(100)]
L = [rn.random()*17/2 for _ in range(100)]
No_party = [[L[i]*cos(theta[i])+c_NO[0],L[i]*sin(theta[i])+c_NO[1],-1] for i in range(50)]

rn.seed(15)
c_NO = (20,20)
theta = [rn.random()*2*pi for _ in range(100)]
L = [rn.random()*17/2 for _ in range(100)]
Si_party = [[L[i]*cos(theta[i])+c_NO[0],L[i]*sin(theta[i])+c_NO[1],1] for i in range(50)]
# juntando la data
dataset_ = Si_party+No_party
dataset = np.array(dataset_)
# Dividiendo 
X_train, X_val, y_train, y_val = train_test_split( dataset[:,0:2], dataset[:,2], test_size=0.2, random_state=43,shuffle=True)

#%%
# Graficamos los datos
plt.figure(1)
plt.plot(dataset[0:50,0],dataset[0:50,1],'o')
plt.plot(dataset[51:,0],dataset[51:,1],'o')
plt.xticks(np.arange(0, max(dataset[:,0]), 1))
plt.rcParams['figure.figsize'] = (8, 6)
plt.xlabel("Edad")
plt.ylabel("Factor de madurez")
plt.title("Dataset Perceptron")
plt.legend(['SI','No'])

plt.show()
#%%
def perceptron_single_step_udate(x_feature,
                                y_label, 
                                current_weight, 
                                current_bias):
    error = y_label*(current_weight.dot(x_feature)+current_bias)
    if error<0 or abs(error)<1e-5:
        current_weight = current_weight + y_label*x_feature
        current_bias   = current_bias + y_label
    return current_weight, current_bias

def full_perceptron(feature_matrix,
                    labels,
                    T):
    weigth = np.array([0 for _ in range(feature_matrix.shape[1])])
    bias = 0
    for t in range(T):
        for x,y in zip(feature_matrix,labels):
            weigth, bias = perceptron_single_step_udate(x,y,weigth,bias)

    return weigth, bias

def accuracy(y_predict, y_real):
    return (y_predict==y_real).mean()

def classify(x_feature, weight, bias):
    z = x_feature.dot(weight)+bias
    for i, val in enumerate(z):
        if val<0 or abs(val)<1e-5:
            z[i] = -1
        else:
            z[i] = 1
    return z
#%%
# PreciciÃ³n del clasificador
weigth, bias = full_perceptron(X_train,y_train,10)
predc = classify(X_val,weigth, bias)
acc = accuracy(predc, y_val)
print('Accuracy val = ', acc)